@InProceedings{10.1007/978-3-030-72113-8_9,
author="Ferreira, Rafael
and Leite, Mariana
and Semedo, David
and Magalhaes, Joao",
editor="Hiemstra, Djoerd
and Moens, Marie-Francine
and Mothe, Josiane
and Perego, Raffaele
and Potthast, Martin
and Sebastiani, Fabrizio",
title="Open-Domain Conversational Search Assistant with Transformers",
booktitle="Advances in  Information Retrieval",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="130--145",
abstract="Open-domain conversational search assistants aim at answering user questions about open topics in a conversational manner. In this paper we show how the Transformer architecture [30] achieves state-of-the-art results in key IR tasks, leveraging the creation of conversational assistants that engage in open-domain conversational search with single, yet informative, answers. In particular, we propose an open-domain abstractive conversational search agent pipeline to address two major challenges: first, conversation context-aware search and second, abstractive search-answers generation. To address the first challenge, the conversation context is modeled with a query rewriting method that unfolds the context of the conversation up to a specific moment to search for the correct answers. These answers are then passed to a Transformer-based re-ranker to further improve retrieval performance. The second challenge, is tackled with recent Abstractive Transformer architectures to generate a digest of the top most relevant passages. Experiments show that Transformers deliver a solid performance across all tasks in conversational search, outperforming the best TREC CAsT 2019 baseline.",
isbn="978-3-030-72113-8"
}

